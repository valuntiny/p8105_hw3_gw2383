---
title: "p8105_hw3_gw2383"
author: "Guojing Wu"
date: "2018/10/7"
# output: html_document
output:
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(p8105.datasets)
library(patchwork)
theme_set(theme_bw())
```

## Problem 1

### data cleaning

```{r}
brfss_df =
  p8105.datasets::brfss_smart2010 %>%
  janitor::clean_names() %>% # cleaning
  rename(location_abbr = locationabbr, location_desc = locationdesc) %>% # format the variable name
  filter(topic == "Overall Health") %>% # focus on the “Overall Health” topic
  filter(response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) %>% # choose response
  arrange(response) # organize responses
```

### some questions

* In 2002, `r names(which(brfss_df %>% filter(year == 2002) %>% distinct(location_abbr, location_desc) %>% select(location_abbr) %>% table() == 7))` states were observed at 7 locations

* spaghetti plot

```{r, dpi=300}
brfss_df %>%
  distinct(year, location_abbr, location_desc) %>%
  group_by(year, location_abbr) %>%
  summarise(n = n()) %>%
  ggplot(aes(x = year, y = n, group = location_abbr, color = location_abbr)) +
  geom_line() +
  labs(
    y = "number of observatons",
    title = " number of observations in each state from 2002 to 2010"
  ) +
  theme_bw()
```

* a table of mean and standard deviation

```{r}
brfss_df %>%
  filter(year %in% c(2002, 2006, 2010) & location_abbr == "NY" & response == "Excellent") %>%
  group_by(year) %>%
  summarise(mean_exc = mean(data_value),
            sd_exc = sd(data_value)) %>% 
   knitr::kable(digits = 1)
```

* a five-panel plot

```{r, dpi=300}
brfss_df %>%
  group_by(year, location_abbr, response) %>%
  summarise(mean_prop = mean(data_value)) %>%
  ggplot(aes(x = year, y = mean_prop, group = location_abbr, color = location_abbr)) +
  geom_line() +
  labs(y = "average proportion") +
  facet_grid(response ~ ., scales = "free") + # ploting vertically and without the same axis scaling
  theme_bw()
```

## Problem 2

```{r}
insta_df = p8105.datasets::instacart %>% 
  janitor::clean_names()
```

### short description

There are `r dim(insta_df)[2]` variables and `r dim(insta_df)[1]` observations in this dataset. It contains details of every order: like `user id`: customer identifier, `order id`: order identifier, `product id`: product identifier, `product name`, `reordered`: whether it's reordered or not, when it was ordered (assume 0 was assigned to Sunday). Also, in the local store, there are `r dim(distinct(insta_df, department))[1]` departments.

```{r} 
insta_df %>% select(user_id, order_id, product_id, product_name, reordered, order_dow) %>% head(10) %>% knitr::kable()
```

### some questions

* There are `r dim(distinct(insta_df, aisle))[1]` aisles in the store. And among them, "`r (insta_df %>% group_by(aisle) %>% summarise(item_sum = n()) %>% arrange(desc(item_sum)))[1,1]`" aisle is the most items ordered from.

* a plot that shows the number of items ordered in each aisle

```{r, fig.height = 20, dpi=300}
# a function for sorting the factors so that aisles will be listed in descending way
reorder_size <- function(x) {
  factor(x, levels = names(sort(table(x))))
}

insta_df %>% 
  select(aisle) %>% 
  ggplot(aes(x = reorder_size(aisle))) +
  geom_bar() +
  scale_y_log10() +
  labs(x = "aisles", 
       y = "log10(total number of items)", 
       title = "number of items ordered in each aisle") +
  coord_flip() # flipping it so that reader can see it clearly
```

* the most popular item:

```{r}
insta_df %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarise(item_num = n()) %>% 
  group_by(aisle) %>% 
  mutate(item_rank = min_rank(desc(item_num))) %>% # calculate the rank
  filter(item_rank == 1) %>% 
  knitr::kable(digits = 1)
```

* a table showing the mean hour of the day

for the consecutive number in order_dow, we assume 0 assign to Sunday, 1 assign to Monday and so on ...

```{r}
insta_df %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  spread(key = order_dow, value = mean_hour) %>% 
  rename(Sunday = "0", Monday = "1", Tuesday = "2", Wednesday = "3", Thursday = "4", Friday = "5", Saturday = "6") %>% # rename it to make it readable
  knitr::kable(digit = 1)
```

## Problem 3

```{r}
noaa_df = p8105.datasets::ny_noaa %>% 
  janitor::clean_names()
```

### short description

There are `r dim(noaa_df)[2]` variables and `r dim(noaa_df)[1]` observations in this dataset. It contains details of everyday weatherr: like `id`: Weather station ID, `date`: Date of observation, `prcp`: Precipitation (tenths of mm), `snow`: Snowfall (mm), `snwd`: Snow depth (mm), `tmax`: aximum temperature (tenths of degrees C), `tmin`: Minimum temperature (tenths of degrees C).

Also we noticed that there are many NAs in the dataset, below are the table of the proportion of NAs in each column

```{r}
noaa_df %>% 
  summarise(id_na = sum(is.na(id))/length(id),
            date_na = sum(is.na(date))/length(date),
            prcp_na = sum(is.na(prcp))/length(prcp),
            snow_na = sum(is.na(snow))/length(snow),
            snwd_na = sum(is.na(snwd))/length(snwd),
            tmax_na = sum(is.na(tmax))/length(tmax),
            tmin_na = sum(is.na(tmin))/length(tmin)
            ) %>% 
  knitr::kable(digits = 3)
```

### some questions

* data cleaning and create separate variables for year, month, and day

```{r}
noaa_df = noaa_df %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% # separate the date
  mutate(prcp = as.numeric(prcp)/10, tmax = as.numeric(tmax)/10, tmin = as.numeric(tmin)/10) %>% # change the unit
  rename(prcp_in_mm = prcp, snow_in_mm = snow, snwd_in_mm = snwd, tmax_in_celsius = tmax, tmin_in_celsius = tmin)
```

Find the most commonly observed values for snowfall:

```{r}
result_1 = noaa_df %>% 
  group_by(snow_in_mm) %>% 
  summarise(observe_num = n()) %>% 
  arrange(desc(observe_num)) %>% # decreasing order
  .[1,]
```

The value is `r result_1[1]`, and it has been observed `r result_1[2]` times.

* a two-panel plot showing the average max temperature in January and in July in each station across years

```{r, fig.height = 20, dpi=300}
noaa_df %>% 
  filter(month %in% c("01", "06")) %>% # choose
  group_by(id, year, month) %>% # group by
  summarise(mean_tmax = mean(tmax_in_celsius, na.rm = T)) %>% # calculate mean
  filter(!is.na(mean_tmax)) %>% # remove NA
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id)) +
  geom_line() +
  facet_grid(month ~ ., scales = "free") +
  theme(
    legend.position = "bottom", 
    axis.text.x = element_text(size = 5), 
    legend.text = element_text(size = 5)
    )
```

As we can see from the plot, it did follow some observable structure. The average temperature follows specific waving pattern: like in January 1994, the temperature in all stations reached their nadir, or in June 1999, the temperature in all stations reached their peak.

But we can also see some outliers: like in January 1982, (`r noaa_df %>% filter(year==1982, month=="01") %>% group_by(id) %>% summarise(mean_tmax = mean(tmax_in_celsius, na.rm = T)) %>% arrange(mean_tmax) %>% .[1,]`) is an outlier, or in June 2004, (`r noaa_df %>% filter(year==2004, month=="06") %>% group_by(id) %>% summarise(mean_tmax = mean(tmax_in_celsius, na.rm = T)) %>% arrange(mean_tmax) %>% .[1,]`) is an outlier too.

* a two-panel plot showing tmax vs tmin for the full dataset

```{r, fig.height = 8, fig.width = 12, dpi=300}
# first make a plot of mean tmax
tmax_plot = 
  noaa_df %>% 
  ggplot(aes(x = year, y = tmax_in_celsius)) +
  geom_violin(aes(fill = year), color = "blue", alpha = 0.5) +
  ylim(-60, 60) +
  stat_summary(fun.y = median, geom = "point", color = "blue", size = 2) +
  theme(legend.position = "none")

# then make a plot of mean tmin
tmin_plot = 
  noaa_df %>% 
  ggplot(aes(x = year, y = tmin_in_celsius)) +
  geom_violin(aes(fill = year), color = "blue", alpha = 0.5) +
  ylim(-60, 60) +
  stat_summary(fun.y = median, geom = "point", color = "blue", size = 2) +
  theme(legend.position = "none")

tmax_plot / tmin_plot
```

a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year

```{r, fig.height = 8, fig.width = 12, dpi=300}
noaa_df %>% 
  filter(snow_in_mm > 0 & snow_in_mm < 100) %>% 
  ggplot(aes(x = year, y = snow_in_mm)) +
  geom_violin(aes(fill = year), color = "blue", alpha = 0.5) +
  stat_summary(fun.y = median, geom = "point", color = "blue", size = 2) +
  theme(legend.position = "none")
```